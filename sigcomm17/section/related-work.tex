\section{Background and Related Work}
\label{sec:relatedwork}



\subsection{NFV Systems}

NFV was introduced by a 2012 white paper \cite{nfv_whitepaper} by telecommunication operators that propose running virtualized network functions on commodity hardware. Since then, a broad range of NFV studies has been seen in the literature, including bridging the gap between specialized hardware and network functions \cite{hwang2015netvm, Han:EECS-2015-155, martins2014clickos, 199352}, scaling and managing NFV systems \cite{gember2012stratos, palkar2015e2}, flow migration among different NF instances \cite{rajagopalan2013split, khalid2016paving, gember2015opennf}, NF replication \cite{rajagopalan2013pico, sherry2015rollback}, and traffic steering \cite{simplifying}. %None of these systems provide a uniform runtime platform to execute network functions.
In these systems, the NF instances are created as software modules running on standard VMs or containers. \nfactor~customizes a uniform runtime platform to run network functions, which enables transparent resilience support for all network functions/service chains in the runtimes. In addition, a dedicated service chain instance is provisioned for each flow, enabled by the actor framework, achieving failure tolerance and high packet processing throughput with ease. Even though modular design introduced by ClickOS  \cite{martins2014clickos} %\cite{kohler2000click}
 simplifies the way how NFs are constructed, advanced control functionalities, \eg, that to enable flow migration, are still not easy to be integrated in NFs following the design. %nowadays there are new demands for NFV system, which require advanced control functionality to be integrated even into the NF softwares.

%Among the advanced control functionality, flow migration and fault tolerance are definitely the two of the most important features.
To achieve flow migration, existing work such as OpenNF \cite{gember2015opennf} and Split/Merge \cite{rajagopalan2013split} require direct modification of the core processing logic of NF software, which is tedious and difficult to achieve. In addition, existing NFV management systems \chuan{add citation} mostly rely on the SDN controllers to carry out the flow migration protocol, involving non-negligible message passing overhead that lowers packet processing speed of the system.
%Finally, the migration process is fully controlled by a  centralized SDN controller, which may not be scalable if there are many NF instances that need flow migration service.
\nfactor~overcomes these issues using a clean separation between NF processing logic and resilience support functionalities, as well as a system design based the distributed actor framework. The actors can be migrated by communicating among themselves without the coordination from a centralized controller. A fast virtual switch is designed to achieve the functionality of a dedicated SDN switch. Only 3 rounds of request-response are needed for achieving flow migration, based on the actor framework and the customized virtual switch, enabling fast flow migration and high packet processing throughput.


Flow replication usually involves check-pointing the entire process image \chuan{clarify what process image this is referring to, NF process?} and creating a replica for the created process image \cite{sherry2015rollback}. Such checkpointing, if not designed properly, may require temporary pause of an NF process, leading to flow packet losses \chuan{this claim does not appear to be rigorous: does all checkingpointing require pausing a process? double check and revise}. \nfactor~is able to checkpoint all states of a flow in a lightweight fashion without introducing large delay, due to xxx \chuan{briefly describe how \nfactor can achieve this}, enabling transparent replication of NFs and service chains.  Existing work \cite{sherry2015rollback} rely on automated tools to extract important state variables for replicating, which xxx\chuan{explain why these tools are not ideal}.

%A NFV system \cite{nfv-white-paper} typically consists of a controller and many VNF instances. Each VNF instance is a virtualized device running NF software. VNF instances are connected into service chains, implementing certain network services, \eg, access service. Packets of a network flow go through the NF instances in a service chain in order before reaching the destination.

%A VNF instance constantly polls a network interface card (NIC) for packets. Using traditional kernel network stack incurs high context switching overhead \cite{martins2014clickos} and greatly compromise the packet processing throughput. To speed things up, hypervisors usually map the memory holding packet buffers directly into the address space of the VNF instances with the help of Intel DPDK\cite{dpdk} or netmap \cite{netmap}. VNF instances then directly fetch packets from the mapped memory area, avoiding expensive context switches. Recent NFV systems \cite{palkar2015e2, Han:EECS-2015-155, sherry2015rollback, martins2014clickos, hwang2015netvm} are all built using similar techniques.


%Even though using DPDK and netmap to improve the performance of packet processing has become a new trend. Existing flow management systems are still using kernel networking stack to implement the communication channel. On contrary, NFActor completely abandons the kernel networking stack, by constructing a reliable transmission module using DPDK. Using this reliable transmission module does not incur any context switches, thereby boosting the message throughput to 6 million messages per second in our evalution.



\subsection{Actor Programming Model.}

The actor programming model has been used as the basic building block for constructing massive, distributed systems\cite{actor-wiki, akka, newell2016optimizing}. Each actor is an independent execution unit, which can be viewed as a logical thread. In the simplest form, an actor contains an internal actor state (\eg, statistic counter, status of peer actors), a mailbox for accepting incoming messages and several message handler functions. An actor can process incoming messages using its message handlers, send messages to other actors through the built-in message passing channel, and create new actors.

There are several popular actor frameworks, \ie, Scala Akka \cite{akka}, Erlang \cite{erlang}, Orleans \cite{Orleans} and C++ Actor Framework \cite{caf}. These actor frameworks have been used to build a broad range of distributed programs, including on-line games and e-commerce. For example, Blizzard (a famous PC game producer) and Groupon/Amazon/eBay (famous e-commerce websites) all use Akka in their production environment \cite{akka}.


Actor model is a natural fit when buildling flow execution context. In a VNF instance, we can create one actor for one flow, and map the flow packet processing to actor message processing. In the mean time, the flow management tasks could be implemented as message handlers on the actor. However, none of the existing actor systems are optimzed for NFV envirnoment. In our initial prototype, we use C++ Actor Framework \cite{caf} to build NFActor, but the performance of that prototype turns out to be not satisfactory. This forces us to make a customized actor model for NFActor and greatly improves the performance.

The actor programming model has been widely used to construct resilient distributed software \cite{erlang, akka, Orleans, caf}. The actors are asynchronous entities that can receive and send messages as if they are running in a dedicated process. The actors usually run on a powerful runtime system \cite{erlang, akka, caf}, enabling them to achieve network transparency. It greatly simplifies programming with actor model. Even though actor programming model is widely used in both the industry and academic worlds, we have not found any related work that leverage actor programming model to construct NFV system, even though there is a natural connection among actor message processing and NF flow processing. Reliazing this problem, we are the first one to introduce actor programming model into NFV system and shows that using actor programming model can really bring benefits for designing NFV applications.

\textbf{Lightweight Execution Context. } There has been a study on constructing lightweight execution context \cite{litton2016light} in kernel. In this work, the authors construct a light weight execution context by creating multiple memory mapping table in the same process. Switching among different memory tables could be viewed as switching among different lightweight execution contexts. NFActor provides a similar execution context, not for kernel processes, but for network functions. Each actor inside NFActor framework actually provides a lightweight execution context for processing a packet along a service chain. Being a lightweight context, the actors do not introduce too much overhead as we can see from the experiment session. On the other hand, packet processing is fully monitored by the execution context, thereby providing a transparent way to migrate and replicate flow states.
